# Part 2：作用于 API 网关的速率限制

> 原文地址：https://blog.getambassador.io/rate-limiting-for-api-gateways-892310a2da02
>
> 作者：[Daniel Bryant](https://www.infoq.com/profile/Daniel-Bryant)
>
> 译者：[李昕阳](https://darrenxyli.com/)

在本速率限制系列的[第一篇文章](https://blog.getambassador.io/rate-limiting-a-useful-tool-with-distributed-systems-6be2b1a4f5f4)中，介绍了实施速率限制的动机，并讨论了几种实施方案（取决于你是否同时作为通信的发送端和接收端）以及相关的权衡。本文会深入探讨 API 网关速率限制的需求。

### 为什么 API 网关需要速率限制
在第一篇文章中，我讨论了在何处实施速率限制的几个选项：发送端，接收端或中间层（字面意思可以理解为发送端和接收端中间的服务）。
当通过公共 API 暴露你的应用程序时，你通常必须在你的接收方或中间件中实施速率限制。即使你控制了源代码（客户端）应用程序，你通常也会希望防止导致过多 API 请求的错误，并且还要应付可能试图破坏客户端应用程序的不良行为者。
Stripe 博客有一篇关于“用限速器扩展你的 API”的精彩文章，我将在本文中引用这篇文章，开头部分将讨论速率限制会如何帮助你在以下情况下让你的 API 更加可靠：

* 某位用户制造了流量洪峰，导致你的应用过载，而你的应用此时还需要为其他人提供服务。
* 某位用户因为使用了行为不当的脚本，它无意中向你发送了很多请求（相信我，这比你想象的要更频繁 - 我曾经亲自创建的压测脚本就意外触发了拒绝服务！）。或者，更糟的是，某位用户试图故意让你的服务器过载。
* 用户向你发送很多优先级较低的请求，而你需要确保它不会影响高优先级的通信。例如，发送大量分析数据请求的用户可能会影响其他用户的关键事务。
* 系统中的出现了某些内部问题，因此无法提供所有常规流量服务，并且需要丢弃低优先级的请求。

在 Datawire 工作期间，我们通常能够第一手地发现以上这些情况，特别是在那些暴露 “免费” 公共 API 的公司或者组织中，同时在这些组织中，存在着明确的业务需求是让付费用户优先使用流量，并且防止不良行为者（无论是有意或无意）。

### 速率限制和减负的基础知识
基本上，要理解速率限制的概念很简单。对于每个要限制的请求属性，只需保持每次查看属性的每个唯一实例的次数，并在每个时间单位超过指定的计数时拒绝关联的请求。 例如，如果你想限制每个客户端发出的请求数量，你将使用“客户端标识”属性（可能通过请求字符串键值“clientID”设置或包含在请求头部中），并为标识符保留一个计数器。

你还可以指定每个时间单元的最大请求数，并且可能会定义计算如何递减的算法，而不是在每个单元开始时重置计数器（稍后会详细介绍）。 当请求到达API网关时，它会递增适当的请求计数并检查这个增加是否意味着每个时间单元的最大允许请求已被超过。 如果是这样，那么这个请求将被拒绝，最常见的情况是向调用客户端返回“Too Many Requests”HTTP 429状态码。

与限速密切相关的是“卸载”。 这里的主要区别在于拒绝流量的决定不是基于单个请求的属性（例如clientId），而是基于应用的总体状态（例如，处于高负载下的数据库）。 如果系统仍处于部分运行状态，但是需要时间来恢复（或修复），则实施在入口点减轻负载的能力可以节省大客户事件。

### API 网关存在的挑战
大多数开放源代码和商业API网关都提供速率限制，但许多这些实现中的挑战之一是可扩展性。在单个计算实例上运行API网关相对简单，这意味着你可以将速率限制计数器保留在内存中。例如，如果你对clientId进行速率限制，则只需使用关联的整数计数器在内存映射中检查并设置（增加）clientId即可。但是，此方法不会扩展单个实例到网关实例的集群。

我见过一些开发人员试图通过使用粘性会话或将可允许请求的总数除以速率限制实例的数量来解决此限制。但是，这样做的问题在于，在高度动态的“云原生”环境中部署和运行应用程序时，这些方法都无法可靠地工作，在这种环境中，实例正在被销毁并按需重新创建，并且也是动态缩放的。

克服此限制的最佳解决方案是使用某种形式的高性能集中式数据存储来管理请求计数。例如，在Lyft，该团队使用Redis（大概是作为高可用性Redis Sentinel集群运行），通过他们的Envoy代理跟踪这个速率限制数据，该代理被部署为所有服务和数据存储的边车。这种方法需要注意一些潜在的问题，特别是在Redis的检查和设置操作的原子性方面。建议出于性能原因避免使用锁定，Stripe和Figma在Redis引擎中使用Lua脚本功能（保证原子性）讨论过。

经常遇到的其他挑战涉及提取用于确定速率限制的请求（元）数据的能力，还指定（或实现）用于确定是否应该拒绝特定请求的相关算法。理想情况下，你希望能够指定与各种客户端属性（例如请求HTTP方法，位置，设备等）相关的速率限制以及后端分解（例如服务端点，语义信息（例如用户发起的请求与应用程序）启动请求，有效负载期望）。

### 通过外部服务进行速率限制
Lyft工程团队去年提出了一个有趣的解决上一节讨论的许多挑战的解决方案，当时他们谈论了他们如何使用Envoy代理（我们现在称之为）服务网格通过调用实现速率限制为每个请求提供外部RateLimit服务。 Ratelimit服务符合这里定义的Ratelimit protobuf，这实际上是一个速率限制API。 Datawire团队已经在Envoy Proxy之上构建了开放源代码的Ambassador API网关，最近Alex Gervais已经为Ambassador提供了相同的速率限制支持。

由于你现在可以访问protobuf速率限制服务API，因此你可以使用任何你喜欢的语言（或至少是任何带protobuf支持的语言，这是最现代化的语言）来实施速率限制服务。你现在还可以完全自由地在服务中实现你喜欢的任何速率限制算法，并且还可以将速率限制决策基于你想要传递给服务的任何元数据。 Lyft RateLimit服务中的示例提供了一些有趣的灵感！值得一提的是，由于Ambassador API网关在Kubernetes内部运行，你创建的任何速率限制服务都可以利用Kubernetes来处理扩展和容错。

### 关于系列文章的下一篇
在我们的速率限制系列的第二篇文章中，阐述了在 API 网关实施速率限制和减负的动机，并且还探讨了实施过程中可能遇到的一些挑战。 在文章的最后一节中，我提出了一些在现代云平台（如Kubernetes，ECS等）中部署集成有速率限制 API 网关的想法，并讨论了如何使用外部服务来实现这一切，以达到在实施你对速率限制算法的要求的同时，还能提供很大灵活性。

下周我们将发布本系列的最后一部分，我们将介绍如何利用 Java 为 Ambassador API 网关实施速率限制服务（[代码链接](https://github.com/danielbryantuk/ambassador-java-rate-limiter/blob/master/src/main/java/io/datawire/ambassador/ratelimiter/simpleimpl/RateLimitServer.java)）。

同时，请随时通过电子邮件发送任何问题，或到 Ambassador 的 [Gitter 频道](https://gitter.im/datawire/ambassador)。